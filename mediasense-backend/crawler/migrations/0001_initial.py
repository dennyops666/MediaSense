# Generated by Django 5.1.4 on 2025-01-13 04:48

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="CrawlerConfig",
            fields=[
                ("id", models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name="ID")),
                ("name", models.CharField(max_length=100, verbose_name="配置名称")),
                ("description", models.TextField(blank=True, verbose_name="配置描述")),
                ("source_url", models.URLField(max_length=500, verbose_name="数据源URL")),
                (
                    "crawler_type",
                    models.IntegerField(choices=[(1, "RSS"), (2, "API"), (3, "网页")], verbose_name="爬虫类型"),
                ),
                ("config_data", models.JSONField(default=dict, verbose_name="配置数据")),
                ("headers", models.JSONField(default=dict, verbose_name="请求头")),
                ("interval", models.IntegerField(default=60, verbose_name="抓取间隔(分钟)")),
                ("status", models.IntegerField(choices=[(0, "禁用"), (1, "启用")], default=0, verbose_name="状态")),
                ("last_run_time", models.DateTimeField(blank=True, null=True, verbose_name="上次运行时间")),
                ("created_at", models.DateTimeField(auto_now_add=True, verbose_name="创建时间")),
                ("updated_at", models.DateTimeField(auto_now=True, verbose_name="更新时间")),
            ],
            options={
                "verbose_name": "爬虫配置",
                "verbose_name_plural": "爬虫配置",
                "ordering": ["-updated_at"],
                "indexes": [models.Index(fields=["status", "-updated_at"], name="crawler_cra_status_d71a10_idx")],
            },
        ),
        migrations.CreateModel(
            name="ProxyPool",
            fields=[
                ("id", models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name="ID")),
                ("ip", models.CharField(max_length=64, verbose_name="IP地址")),
                ("port", models.IntegerField(verbose_name="端口号")),
                (
                    "protocol",
                    models.CharField(
                        choices=[("http", "HTTP"), ("https", "HTTPS")], max_length=10, verbose_name="协议"
                    ),
                ),
                ("location", models.CharField(blank=True, max_length=100, verbose_name="地理位置")),
                ("speed", models.IntegerField(default=0, verbose_name="响应速度(ms)")),
                ("success_rate", models.FloatField(default=0.0, verbose_name="成功率")),
                (
                    "status",
                    models.IntegerField(
                        choices=[(0, "未验证"), (1, "可用"), (2, "不可用")], default=0, verbose_name="状态"
                    ),
                ),
                ("last_check_time", models.DateTimeField(blank=True, null=True, verbose_name="最后检查时间")),
                ("created_at", models.DateTimeField(auto_now_add=True, verbose_name="创建时间")),
                ("updated_at", models.DateTimeField(auto_now=True, verbose_name="更新时间")),
            ],
            options={
                "verbose_name": "代理池",
                "verbose_name_plural": "代理池",
                "db_table": "crawler_proxy_pool",
                "ordering": ["-success_rate", "speed"],
                "indexes": [
                    models.Index(fields=["status", "protocol"], name="crawler_pro_status_06ab2d_idx"),
                    models.Index(fields=["success_rate", "speed"], name="crawler_pro_success_3c8336_idx"),
                ],
            },
        ),
        migrations.CreateModel(
            name="CrawlerTask",
            fields=[
                ("id", models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name="ID")),
                ("task_id", models.CharField(max_length=100, unique=True, verbose_name="任务ID")),
                (
                    "status",
                    models.IntegerField(
                        choices=[(0, "未开始"), (1, "运行中"), (2, "已完成"), (3, "已停止"), (4, "出错")],
                        default=0,
                        verbose_name="状态",
                    ),
                ),
                ("start_time", models.DateTimeField(blank=True, null=True, verbose_name="开始时间")),
                ("end_time", models.DateTimeField(blank=True, null=True, verbose_name="结束时间")),
                ("result", models.JSONField(default=dict, verbose_name="执行结果")),
                ("error_message", models.TextField(blank=True, verbose_name="错误信息")),
                ("created_at", models.DateTimeField(auto_now_add=True, verbose_name="创建时间")),
                ("updated_at", models.DateTimeField(auto_now=True, verbose_name="更新时间")),
                (
                    "config",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE, to="crawler.crawlerconfig", verbose_name="爬虫配置"
                    ),
                ),
            ],
            options={
                "verbose_name": "爬虫任务",
                "verbose_name_plural": "爬虫任务",
                "ordering": ["-created_at"],
                "indexes": [
                    models.Index(fields=["config", "-created_at"], name="crawler_cra_config__891938_idx"),
                    models.Index(fields=["status", "-created_at"], name="crawler_cra_status_123435_idx"),
                ],
            },
        ),
    ]
